{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# import contractions\n",
    "# import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_links_characters(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text\n",
    "\n",
    "def regular_preprocess(text):\n",
    "    text = remove_html(text)\n",
    "    text = remove_links_characters(text)\n",
    "    # text = replace_contractions(text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(docs, stopwords):\n",
    "    docs_ref = []\n",
    "    for doc in docs:\n",
    "        word_list = doc.lower().split()\n",
    "        word_list_ref = [word for word in word_list if word not in stopwords]\n",
    "        word_str_ref = ' '.join(word_list_ref)\n",
    "        docs_ref.append(word_str_ref)\n",
    "    return docs_ref\n",
    "\n",
    "def stem_words(docs):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    for doc in docs:\n",
    "        word_list = doc.lower().split()\n",
    "        for word in word_list:\n",
    "            stem = stemmer.stem(word)\n",
    "            stems.append(stem)\n",
    "        stems_str = ' '.join(stems)\n",
    "        stems.append(stems_str)\n",
    "    return stems\n",
    "\n",
    "def preprocess(data):\n",
    "    refined_data = []\n",
    "    for dp in data:\n",
    "        refined_data.append(regular_preprocess(dp))        \n",
    "    return refined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking that it could only get better was the worst assumption I ever made....<br /><br />Drivvle does not describe this movie appropriately enough!<br /><br />Not only is the plot thin, but I get more emotional acting from my pet fish!<br /><br />It was a shame to see Pete Postlethwaite, whom I respect as an actor trying to do the best with the little he had to work with...<br /><br />I think that a cardboard cut out of Stephen Baldwin would have done a better job , and in fact have been more animate.<br /><br />Avoid at all costs! This could really be hazardous to your health!\n",
      "Thinking that it could only get better was the worst assumption I ever made....Drivvle does not describe this movie appropriately enough!Not only is the plot thin, but I get more emotional acting from my pet fish!It was a shame to see Pete Postlethwaite, whom I respect as an actor trying to do the best with the little he had to work with...I think that a cardboard cut out of Stephen Baldwin would have done a better job , and in fact have been more animate.Avoid at all costs! This could really be hazardous to your health!\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 41.6min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9052\n"
     ]
    }
   ],
   "source": [
    "# copy contents of all files in both folders into a list\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# copy contents of all files in both folders into a list\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# train data\n",
    "train_neg = glob.glob(os.path.join(os.getcwd(), \"Dataset/train/neg\", \"*.txt\"))\n",
    "for f_path in train_neg:\n",
    "    with open(f_path) as f:\n",
    "        train_data.append(f.read())\n",
    "\n",
    "train_pos = glob.glob(os.path.join(os.getcwd(), \"Dataset/train/pos\", \"*.txt\"))\n",
    "for f_path in train_pos:\n",
    "    with open(f_path) as f:\n",
    "        train_data.append(f.read())\n",
    "# print(train_data[0])\n",
    "# print(preprocess(train_data[0]))\n",
    "\n",
    "# test data\n",
    "def sort_nicely(l):\n",
    "# Sort the given list in the way that humans expect.\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    l.sort(key=alphanum_key)\n",
    "\n",
    "test_files = glob.glob(os.path.join(os.getcwd(), \"Dataset/test\", \"*.txt\"))\n",
    "sort_nicely(test_files)\n",
    "test_files_ids = [int(re.sub(\"[^0-9]\",\"\", item)) for item in test_files]\n",
    "\n",
    "for f_path in test_files:\n",
    "    with open(f_path) as f:\n",
    "        test_data.append(f.read())\n",
    "\n",
    "# targets: first 12500 are pos, next 12500 are neg\n",
    "targets = [0 if i<12500 else 1 for i in range(25000)]\n",
    "\n",
    "with open('english') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "    \n",
    "print(test_data[0])\n",
    "train_data_clean = preprocess(train_data)\n",
    "# train_data_clean = remove_stopwords(train_data_clean, stopwords)\n",
    "# train_data_clean = stem_words(train_data_clean)\n",
    "test_data_clean = preprocess(test_data)\n",
    "# test_data_clean = remove_stopwords(test_data_clean, stopwords)\n",
    "# test_data_clean = stem_words(test_data_clean)\n",
    "print(test_data_clean[0])\n",
    "\n",
    "\n",
    "# splitting the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_data_clean, targets, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "pclf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('norm', Normalizer()),\n",
    "#     ('best', TruncatedSVD(n_components=10000)),\n",
    "    # ('clf', LogisticRegression()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "params = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 10000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),(2,2)),  # unigrams or bigrams\n",
    "    'clf__max_iter': (5,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "#     'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "# def report(results, n_top=3):\n",
    "#     for i in range(1, n_top + 1):\n",
    "#         candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "#         for candidate in candidates:\n",
    "#             print(\"Model with rank: {0}\".format(i))\n",
    "#             print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "#                   results['mean_test_score'][candidate],\n",
    "#                   results['std_test_score'][candidate]))\n",
    "#             print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "#             print(\"\")\n",
    "            \n",
    "grid_search = GridSearchCV(pclf, params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y1_pred = grid_search.predict(X_validation)\n",
    "y_pred = grid_search.predict(test_data_clean)\n",
    "\n",
    "# random_search = RandomizedSearchCV(pclf, param_distributions = params, cv=2, verbose = 10, random_state = 1, n_iter = 1)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# report(random_search.cv_results_)\n",
    "\n",
    "# y_pred = random_search.predict(X_validation)\n",
    "\n",
    "# def display_results(y_val, y_pred):\n",
    "#     print(metrics.classification_report(y_val, y_pred))\n",
    "#     print(\"Accuracy % = \", metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "# pclf.fit(X_train, y_train)\n",
    "# y_pred = pclf.predict(X_validation)\n",
    "# print(y_pred)\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow((\"Id\", \"Category\"))\n",
    "    writer.writerows(zip(test_files_ids, y_pred))\n",
    "\n",
    "# display_results(y_validation, y_pred)\n",
    "print(metrics.accuracy_score(y_validation, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def advanced_preprocess(text):\n",
    "# #     words = nltk.word_tokenize(text)\n",
    "#     words = replace_numbers(text)\n",
    "#     words = remove_non_ascii(words)\n",
    "#     words = to_lowercase(words)\n",
    "#     words = remove_stopwords(words)\n",
    "#     words = stem_words(words)\n",
    "#     return words\n",
    "\n",
    "# def replace_contractions(text):\n",
    "#     \"\"\"Replace contractions in string of text\"\"\"\n",
    "#     return contractions.fix(text)\n",
    "#\n",
    "# def stem_words(words):\n",
    "#     \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stems = []\n",
    "#     for word in words:\n",
    "#         stem = stemmer.stem(word)\n",
    "#         stems.append(stem)\n",
    "#     return stems\n",
    "#\n",
    "# def replace_numbers(words):\n",
    "#     \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "#     p = inflect.engine()\n",
    "#     new_words = []\n",
    "#     for word in words:\n",
    "#         if word.isdigit():\n",
    "#             new_word = p.number_to_words(word)\n",
    "#             new_words.append(new_word)\n",
    "#         else:\n",
    "#             new_words.append(word)\n",
    "#     return new_words\n",
    "#\n",
    "# def lemmatize_verbs(words):\n",
    "#     \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     lemmas = []\n",
    "#     for word in words:\n",
    "#         lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "#         lemmas.append(lemma)\n",
    "#     return lemmas\n",
    "#\n",
    "# def to_lowercase(words):\n",
    "#     \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "#     new_words = []\n",
    "#     for word in words:\n",
    "#         new_word = word.lower()\n",
    "#         new_words.append(new_word)\n",
    "#     return new_words\n",
    "#\n",
    "# def remove_non_ascii(words):\n",
    "#     \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "#     new_words = []\n",
    "#     for word in words:\n",
    "#         new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "#         new_words.append(new_word)\n",
    "#     return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag of Words vectorization\n",
    "cv = CountVectorizer(binary=True).fit(X_train)\n",
    "X_train_counts = cv.transform(X_train)\n",
    "X_validation_counts = cv.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      2488\n",
      "           1       0.84      0.88      0.86      2512\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "Accuracy % =  0.8556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_NB = MultinomialNB().fit(X_train_counts, y_train)\n",
    "y_pred = clf_NB.predict(X_validation_counts)\n",
    "\n",
    "# X_train_normalized = np.array(X_train_normalized)\n",
    "\n",
    "# print(X_train_normalized.shape)\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      2488\n",
      "           1       0.89      0.87      0.88      2512\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n",
      "Accuracy % =  0.8814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_LR = LogisticRegression().fit(X_train_counts, y_train)\n",
    "y_pred = clf_LR.predict(X_validation_counts)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# clf_DT = DecisionTreeClassifier().fit(X_train_counts, y_train)\n",
    "# y_pred = clf_DT.predict(X_validation_counts)\n",
    "\n",
    "# print(metrics.classification_report(y_validation, y_pred))\n",
    "# print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      2488\n",
      "           1       0.87      0.86      0.87      2512\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Accuracy % =  0.8656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_SVM = LinearSVC().fit(X_train_counts, y_train)\n",
    "y_pred = clf_SVM.predict(X_validation_counts)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer(binary=True) with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Bag of Words vectorization\n",
    "cv = CountVectorizer(binary=True).fit(X_train)\n",
    "X_train_counts = cv.transform(X_train)\n",
    "X_validation_counts = cv.transform(X_validation)\n",
    "\n",
    "# tfidf\n",
    "tfidf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "X_validation_tfidf = tfidf_transformer.transform(X_validation_counts)\n",
    "\n",
    "# normalization\n",
    "normalizer_tranformer = Normalizer().fit(X=X_train_tfidf)\n",
    "X_train_normalized = normalizer_tranformer.transform(X_train_tfidf)\n",
    "X_validation_normalized = normalizer_tranformer.transform(X_validation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68499)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      2488\n",
      "           1       0.85      0.89      0.87      2512\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Accuracy % =  0.8654\n"
     ]
    }
   ],
   "source": [
    "clf_NB = MultinomialNB().fit(X_train_normalized, y_train)\n",
    "y_pred = clf_NB.predict(X_validation_normalized)\n",
    "\n",
    "# X_train_normalized = np.array(X_train_normalized)\n",
    "\n",
    "print(X_train_normalized.shape)\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2488\n",
      "           1       0.91      0.88      0.89      2512\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n",
      "Accuracy % =  0.8944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_LR = LogisticRegression().fit(X_train_normalized, y_train)\n",
    "y_pred = clf_LR.predict(X_validation_normalized)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# clf_DT = DecisionTreeClassifier().fit(X_train_normalized, y_train)\n",
    "# y_pred = clf_DT.predict(X_validation_normalized)\n",
    "\n",
    "# print(metrics.classification_report(y_validation, y_pred))\n",
    "# print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      2488\n",
      "           1       0.90      0.88      0.89      2512\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n",
      "Accuracy % =  0.8946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_SVM = LinearSVC().fit(X_train_normalized, y_train)\n",
    "y_pred = clf_SVM.predict(X_validation_normalized)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words vectorization\n",
    "cv = CountVectorizer().fit(X_train)\n",
    "X_train_counts = cv.transform(X_train)\n",
    "X_validation_counts = cv.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      2488\n",
      "           1       0.83      0.88      0.85      2512\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Accuracy % =  0.846\n"
     ]
    }
   ],
   "source": [
    "clf_NB = MultinomialNB().fit(X_train_counts, y_train)\n",
    "y_pred = clf_NB.predict(X_validation_counts)\n",
    "\n",
    "# X_train_normalized = np.array(X_train_normalized)\n",
    "\n",
    "# print(X_train_normalized.shape)\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      2488\n",
      "           1       0.90      0.88      0.89      2512\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n",
      "Accuracy % =  0.8896\n"
     ]
    }
   ],
   "source": [
    "clf_LR = LogisticRegression().fit(X_train_counts, y_train)\n",
    "y_pred = clf_LR.predict(X_validation_counts)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_DT = DecisionTreeClassifier().fit(X_train_counts, y_train)\n",
    "# y_pred = clf_DT.predict(X_validation_counts)\n",
    "\n",
    "# print(metrics.classification_report(y_validation, y_pred))\n",
    "# print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      2488\n",
      "           1       0.88      0.86      0.87      2512\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Accuracy % =  0.8686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_SVM = LinearSVC().fit(X_train_counts, y_train)\n",
    "y_pred = clf_SVM.predict(X_validation_counts)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer() with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag of Words vectorization\n",
    "cv = CountVectorizer().fit(X_train)\n",
    "X_train_counts = cv.transform(X_train)\n",
    "X_validation_counts = cv.transform(X_validation)\n",
    "\n",
    "# tfidf\n",
    "tfidf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "X_validation_tfidf = tfidf_transformer.transform(X_validation_counts)\n",
    "\n",
    "# normalization\n",
    "normalizer_tranformer = Normalizer().fit(X=X_train_tfidf)\n",
    "X_train_normalized = normalizer_tranformer.transform(X_train_tfidf)\n",
    "X_validation_normalized = normalizer_tranformer.transform(X_validation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68354)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      2517\n",
      "           1       0.88      0.84      0.86      2483\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Accuracy % =  0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB().fit(X_train_normalized, y_train)\n",
    "y_pred = clf_NB.predict(X_validation_normalized)\n",
    "\n",
    "# X_train_normalized = np.array(X_train_normalized)\n",
    "\n",
    "print(X_train_normalized.shape)\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2517\n",
      "           1       0.88      0.90      0.89      2483\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n",
      "Accuracy % =  0.8944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression().fit(X_train_normalized, y_train)\n",
    "y_pred = clf_LR.predict(X_validation_normalized)\n",
    "\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_DT = DecisionTreeClassifier().fit(X_train_normalized, y_train)\n",
    "# y_pred = clf_DT.predict(X_validation_normalized)\n",
    "\n",
    "# print(metrics.classification_report(y_validation, y_pred))\n",
    "# print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.7858\n",
      "Accuracy for C=0.005: 0.8366\n",
      "Accuracy for C=0.01: 0.857\n",
      "Accuracy for C=0.05: 0.8856\n",
      "Accuracy for C=0.1: 0.8976\n",
      "Accuracy for C=0.5: 0.899\n",
      "Accuracy for C=0.6: 0.8974\n",
      "Accuracy for C=0.55: 0.8986\n",
      "Accuracy for C=0.45: 0.899\n",
      "Accuracy for C=1.0: 0.8952\n",
      "Accuracy for C=1.5: 0.8932\n",
      "Accuracy for C=0.525: 0.8988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.6, 0.55, 0.45, 1.0, 1.5, 0.525]:\n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train_normalized, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, metrics.accuracy_score(y_validation, svm.predict(X_validation_normalized))))\n",
    "\n",
    "# clf_SVM = LinearSVC().fit(X_train_normalized, y_train)\n",
    "# y_pred = clf_SVM.predict(X_validation_normalized)\n",
    "\n",
    "# print(metrics.classification_report(y_validation, y_pred))\n",
    "# print(\"Accuracy % = \", metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
